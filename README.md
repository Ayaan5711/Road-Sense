# ğŸš¦ RoadSense: Intelligent Traffic Monitoring & Accident Detection System

RoadSense is an AI-powered, real-time vehicle tracking, traffic analytics, and accident detection system. It leverages advanced computer vision techniques including YOLOv8 for vehicle detection, ByteTrack for tracking, and a custom DenseNet201 + ANN pipeline for accident classification. A FastAPI backend serves an interactive dashboard with live video streaming and real-time alerts.

## ğŸ“· Key Features

* ğŸš˜ Vehicle Detection using YOLOv8
* ğŸ“ Zone-based Traffic Monitoring
* ğŸ“Š Traffic Density & Vehicle Type Statistics
* ğŸš¦ Real-time Speed Estimation via Perspective Transform
* âš ï¸ Accident Detection using YOLOv8 + AABB + DenseNet201 + ANN Classifier
* ğŸ”Š Alerts for Overspeeding, Proximity, Stopped Vehicles & Accidents
* ğŸ“ Per-frame Logging to vehicle-tracking.txt and accident-log.txt
* ğŸ–¥ï¸ FastAPI Dashboard for Live Analytics and Stream Switching (live/static/accident)

## ğŸ“ Project Structure

```bash
RoadSense/
â”œâ”€â”€ app.py                    # FastAPI backend with endpoints
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov8s.pt            # Vehicle Detection Model
â”‚   â””â”€â”€ model_epoch_50.pth    # Accident Detection Model 
â”œâ”€â”€ src/
|   â”œâ”€â”€ processing.py         # Core frame processing logic (detection, tracking, logging)
â”‚   â”œâ”€â”€ accident_detection.py # Modular accident detection pipeline
â”‚   â”œâ”€â”€ tracking_utils.py     # ByteTrack integration
â”‚   â”œâ”€â”€ video_utils.py        # YouTube/local stream handler
â”‚   â”œâ”€â”€ zone_utils.py         # Polygonal zone management
â”‚   â”œâ”€â”€ transform_utils.py    # Perspective transform & speed conversion
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/                  # Styling for dashboard
â”‚   â””â”€â”€ js/                   # Optional: frontend scripts
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ landing.html          # Welcome page
â”‚   â”œâ”€â”€ cameraAngles.html     # Choose camera mode
â”‚   â””â”€â”€ tracking.html         # Live video + analytics display
â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ recorded_stream_large.mp4
â”‚   â””â”€â”€ accident_t2.mp4
â”œâ”€â”€ vehicle-tracking.txt     # Per-frame traffic log
â”œâ”€â”€ accident-log.txt         # Confirmed accidents log
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation
```

## ğŸš€ How It Works

1. ğŸ¥ Capture video from YouTube or local source using vidgear/OpenCV.
2. ğŸ§  Run YOLOv8 detection on each frame.
3. ğŸ¯ Track vehicles using ByteTrack.
4. ğŸš— Estimate speed using vertical position history + perspective transform.
5. ğŸ›‘ Detect accidents using a pipeline:

    AABB overlap â†’ Crop pair â†’ DenseNet201 feature extract â†’ ANN prediction
6. ğŸ’¡ Overlay annotations, log results, and stream to FastAPI frontend.


## ğŸ–¥ï¸ System Architecture

The application follows a modular pipeline architecture:

1.  **Video Input:** The system captures frames from a video source (local file or live stream) using OpenCV.
2.  **Detection & Tracking:** Each frame is passed to the YOLOv8 model for vehicle detection. The resulting detections are then fed into the ByteTrack algorithm to track objects across frames.
3.  **Data Processing (`processing.py`):** Custom logic is applied to the tracked objects to:
    -   Check which zone they are in.
    -   Calculate their speed.
    -   Check for proximity to other vehicles.
    -   Count vehicles per zone and type.
4.  **Accident Detection:** A separate pipeline runs for the accident-focused video mode, using a specialized model to identify crash events.
5.  **FastAPI Backend (`app.py`):**
    -   Serves the processed and annotated video stream.
    -   Provides REST API endpoints for the frontend to fetch live data (traffic stats, alerts, analytics).
6.  **Web Dashboard (UI):** A web browser renders the `tracking.html` template, which displays the video feed and uses JavaScript to periodically call the API endpoints to refresh the data dashboards.


## ğŸ§  Accident Detection Pipeline

* Detection: YOLOv8 bounding boxes
* Collision Check: Axis-Aligned Bounding Box overlap
* Feature Extraction: DenseNet201 (pretrained)
* Classification: ANN model with confidence threshold (e.g., 0.82)
* Result: Snapshot saved, accident-log.txt updated, alert sent to UI

## ğŸ–¥ï¸ FastAPI Endpoints

* / : Landing page
* /camera-angles : Choose mode (live / static / accident)
* /set-camera-mode/{mode}
* /video : MJPEG stream
* /live-streaming : Dashboard with vehicle logs
* /log : JSON log of all vehicle tracking data
* /accident-log : JSON log of accidents
* /api/traffic-stats : Per-zone stats
* /api/alerts : Real-time alerts
* /api/analytics : Graph analytics (counts, speed, type dist.)
* /api/accident-detection : List of accident snapshot events

## âš™ï¸ Installation

1. Clone the repository:

```bash
git clone https://github.com/Ayaan5711/Road-Sense.git
cd Road-Sense
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Download YOLOv8 and DenseNet201 weights and place in appropriate folders.

4. Run the app:

```bash
python app.py
```

Then open: [http://127.0.0.1:8000](http://127.0.0.1:8000) in your browser.

## ğŸ“¦ Requirements

* Python 3.8+
* OpenCV
* Ultralytics YOLO
* Supervision
* Torch + torchvision
* FastAPI
* Uvicorn
* vidgear
* scikit-learn, numpy, pandas

## ğŸ“¸ Snapshots

All detected accidents save snapshots with cropped vehicles. These are useful for audits, retraining, and reports.

## ğŸ“ˆ Example Use Cases

* Smart Traffic Monitoring by City Authorities
* Accident Detection for Surveillance
* Traffic Pattern Analytics for Urban Planning
* Research in Intelligent Transport Systems (ITS)

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

* [YOLOv8 by Ultralytics](https://github.com/ultralytics/ultralytics)
* [Supervision by Roboflow](https://github.com/roboflow/supervision)
* [OpenCV](https://opencv.org/)
* [FastAPI](https://fastapi.tiangolo.com/)
* Special thanks to the traffic safety research community


## ğŸ“¬ Contact

For questions or collaborations, please reach out to:

* Team Decodians

